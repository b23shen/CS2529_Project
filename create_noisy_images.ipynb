{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e41fa9dc",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a092fb4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.fft import fft2, ifft2\n",
    "import numpy as np\n",
    "from utils.create_noisy_images_utils import BSDS300Dataset\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision.transforms import Compose, ToTensor, Lambda\n",
    "from utils.models import Unet\n",
    "import statistics\n",
    "import skimage.io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5361aae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6deb6cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BlurredBSDS300Dataset(BSDS300Dataset):\n",
    "    def __init__(self, root='./data/BSDS300', patch_size=32, split='train', use_patches=True,\n",
    "                 kernel_size=7, sigma=2, return_kernel=True):\n",
    "        super(BlurredBSDS300Dataset, self).__init__(root, patch_size, split)\n",
    "\n",
    "        # trim images to even size\n",
    "        self.images = self.images[..., :-1, :-1]\n",
    "        self.kernel_size = kernel_size\n",
    "        self.return_kernel = return_kernel\n",
    "\n",
    "        # extract blur kernel (use an MNIST digit)\n",
    "        self.kernel_dataset = MNIST('./', train=True, download=True,\n",
    "                                    transform=Compose([Lambda(lambda x: np.array(x)),\n",
    "                                                       ToTensor(),\n",
    "                                                       Lambda(lambda x: x / torch.sum(x))]))\n",
    "\n",
    "        kernels = torch.cat([x[0] for (x, _) in zip(self.kernel_dataset, np.arange(self.images.shape[0]))])\n",
    "        kernels = torch.nn.functional.interpolate(kernels[:, None, ...], size=2*(kernel_size,))\n",
    "        kernels = kernels / torch.sum(kernels, dim=(-1, -2), keepdim=True)\n",
    "        self.kernel = kernels[[0]].repeat(kernels.shape[0], 1, 1, 1)\n",
    "\n",
    "        # blur the images\n",
    "        H = psf2otf(self.kernel, self.images.shape)\n",
    "        self.blurred_images = ifft2(fft2(self.images) * H).real\n",
    "        self.blurred_patches = self.patchify(self.blurred_images, patch_size)\n",
    "\n",
    "        # save which blur kernel is used for each image\n",
    "        self.patch_kernel = self.kernel.repeat(1, len(self.blurred_patches) // len(self.images), 1, 1)\n",
    "        self.patch_kernel = self.patch_kernel.view(-1, *self.kernel.shape[-2:])\n",
    "\n",
    "        # reshape kernel\n",
    "        self.kernel = self.kernel.squeeze()\n",
    "\n",
    "    def get_kernel(self, kernel_size, sigma):\n",
    "        kernel = self.gaussian(kernel_size, sigma)\n",
    "        kernel_2d = torch.matmul(kernel.unsqueeze(-1), kernel.unsqueeze(-1).t())\n",
    "        return kernel_2d\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        out = [self.blurred_images[idx][None, ...].to(device),\n",
    "               self.images[idx][None, ...].to(device)]\n",
    "        if self.return_kernel:\n",
    "            out.append(self.kernel[[idx]].to(device))\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "25b7dd96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_to_numpy(x):\n",
    "    return np.clip(x.detach().cpu().numpy().squeeze().transpose(1, 2, 0), 0, 1)\n",
    "\n",
    "\n",
    "def psf2otf(psf, shape):\n",
    "    inshape = psf.shape\n",
    "    psf = torch.nn.functional.pad(psf, (0, shape[-1] - inshape[-1], 0, shape[-2] - inshape[-2], 0, 0))\n",
    "\n",
    "    # Circularly shift OTF so that the 'center' of the PSF is [0,0] element of the array\n",
    "    psf = torch.roll(psf, shifts=(-int(inshape[-1] / 2), -int(inshape[-2] / 2)), dims=(-1, -2))\n",
    "\n",
    "    # Compute the OTF\n",
    "    otf = fft2(psf)\n",
    "\n",
    "    return otf\n",
    "\n",
    "\n",
    "def calc_psnr(x, gt):\n",
    "    out = 10 * np.log10(1 / ((x - gt)**2).mean().item())\n",
    "    return out\n",
    "\n",
    "\n",
    "def wiener_deconv(x, kernel):\n",
    "    snr = 100  # use this SNR parameter for your results\n",
    "    H = psf2otf(kernel, x.shape).to(device)\n",
    "    G = torch.conj(H) * 1/(1/snr + H*torch.conj(H)).to(device)\n",
    "    return ifft2(fft2(x) * G).real\n",
    "\n",
    "\n",
    "def load_models():\n",
    "    model_deblur_denoise = Unet().to(device)\n",
    "    model_deblur_denoise.load_state_dict(torch.load('utils/models/pretrained/deblur_denoise.pth', map_location=device))\n",
    "\n",
    "    model_denoise = Unet().to(device)\n",
    "    model_denoise.load_state_dict(torch.load('utils/models/pretrained/denoise.pth', map_location=device))\n",
    "\n",
    "    return model_deblur_denoise, model_denoise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4cc1afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model():\n",
    "\n",
    "    # create the dataset\n",
    "    dataset = BlurredBSDS300Dataset(split='test')\n",
    "\n",
    "    # load the models\n",
    "    model_deblur_denoise, model_denoise = load_models()\n",
    "\n",
    "    # put into evaluation mode\n",
    "    model_deblur_denoise.eval()\n",
    "    model_denoise.eval()\n",
    "    \n",
    "    PSNRs = []\n",
    "\n",
    "    for sigma in [0.02]:\n",
    "        \n",
    "        psnr_m1 = []\n",
    "        psnr_m2 = []\n",
    "        psnr_m3 = []\n",
    "        \n",
    "        index = 0\n",
    "\n",
    "        for image, gt, kernel in dataset:\n",
    "\n",
    "            ################################################################################\n",
    "            # TODO: Your code goes here!\n",
    "            ################################################################################\n",
    "            pass\n",
    "\n",
    "            # add noise to the image\n",
    "            \n",
    "            image = image + sigma * torch.tensor(np.random.randn(*image.shape)).to(device)\n",
    "\n",
    "            # apply each method (wiener deconvolution and the two networks)\n",
    "            \n",
    "            # Method 1: Wiener deconvolution\n",
    "            \n",
    "            image_deconv = wiener_deconv(image, kernel)\n",
    "            \n",
    "            psnr_m1.append(calc_psnr(image_deconv, gt))\n",
    "            \n",
    "            # Method 2: Neural Network for deconvolution + denoising\n",
    "            \n",
    "            image_neural = model_deblur_denoise(image.to(dtype=torch.float))\n",
    "            \n",
    "            psnr_m2.append(calc_psnr(image_neural, gt))\n",
    "            \n",
    "            # Method 3: Wiener deconvolution + Neural Network denoising\n",
    "            \n",
    "            image_deconv_neural = model_denoise(image_deconv.to(dtype=torch.float))\n",
    "            \n",
    "            psnr_m3.append(calc_psnr(image_deconv_neural, gt))\n",
    "\n",
    "            filename = 'data/noisy_images/'\n",
    "            skimage.io.imsave(filename + str(index) + '_gt.png', (img_to_numpy(gt)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_noisy.png', (img_to_numpy(image)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_deconv.png', (img_to_numpy(image_deconv)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_neural.png', (img_to_numpy(image_neural)*255).astype(np.uint8))\n",
    "            skimage.io.imsave(filename + str(index) + '_deconv_neural.png', (img_to_numpy(image_deconv_neural)*255).astype(np.uint8))\n",
    "            \n",
    "            index = index + 1\n",
    "    \n",
    "        PSNRs.append(statistics.mean(psnr_m1))\n",
    "        PSNRs.append(statistics.mean(psnr_m2))\n",
    "        PSNRs.append(statistics.mean(psnr_m3))\n",
    "    \n",
    "    print(PSNRs)\n",
    "\n",
    "            # save the psnrs\n",
    "\n",
    "            # save out sample images to include in your writeup\n",
    "\n",
    "            # HINT: use the calc_psnr function to calculate the PSNR, and use the\n",
    "            # wiener_deconv function to perform wiener deconvolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "97258c21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.046599738102696, 26.93645977897099, 29.30034218455255]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    evaluate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12544482",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python3.7 (Comp Img)",
   "language": "python",
   "name": "compimg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
